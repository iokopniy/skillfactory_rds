{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные ноутбук служит для обогащения данных по ценовому диапазону и кухням с сайта Trip Advisor по тем записям в которых они не заполнены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import ast \n",
    "import datetime \n",
    "warnings.simplefilter('ignore')\n",
    "import grequests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from lxml import html\n",
    "pd.set_option('display.max_rows', 50)  # показывать больше строк\n",
    "pd.set_option('display.max_columns', 50)  # показывать больше колонок\n",
    "\n",
    "# Добавим метод чтобы красиво отобржать текст\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#поскольку загрузка проводилась в несколько итераций, то предварительно мы сделали копию нашего датасета под новым именем и сохраняли туда промежуточные результаты    \n",
    "df = pd.read_csv('main_task_enriched_Price_Cuisine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#процедура парсинга данных. на вход получает линк на страничку ресторана, на выходе ценовой диапазон и стили кухни\n",
    "def get_data (link):\n",
    " url = 'https://www.tripadvisor.ru'+link\n",
    " with grequests.Session() as session:\n",
    "   session.headers['Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'\n",
    "   session.headers['User-Agent'] = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 ' \\\n",
    "                                        '(KHTML, like Gecko) Chrome/91.0.4472.164 Safari/537.36'\n",
    "   try:\n",
    "     resp = session.get(url, timeout=10)\n",
    "     soup = BS(resp.content, 'lxml')\n",
    "   except:\n",
    "     print('no connection/empty data')\n",
    " try:\n",
    "  money = str(soup.find(class_='_2mn01bsa').contents[0])\n",
    " except:\n",
    "  money=None  \n",
    " try:\n",
    "  cuisine = soup.find('div',class_='ppr_rup ppr_priv_enable_cpm_desktop')\n",
    " #print (str(cuisine).find('cuisine'))\n",
    " #cuisine = soup.find('div', {'class': ['_60ofm15k', '_1XLfiSsv']}).contents\n",
    " #a=str(cuisine).find('cuisine')\n",
    "  cous=str(cuisine)[str(cuisine).find('cuisine'):]\n",
    " #print (cous[cous.find('['):(cous.find(']')+1)])\n",
    "  cousines=cous[cous.find('['):(cous.find(']')+1)]\n",
    " except:\n",
    "  cousines=None\n",
    " #try:\n",
    " # tot_count=str(resp.content)[str(resp.content).find('totalCount'):]\n",
    " # tot_count=tot_count[tot_count.find(':')+1:tot_count.find(',')]\n",
    " #except:\n",
    " # tot_count=None\n",
    " #try:\n",
    " # rev_count=str(resp.content)[str(resp.content).find('reviewSummary'):]\n",
    " # rev_count=rev_count[rev_count.find('\"count\":')+8:rev_count.find(',')]\n",
    " #except:\n",
    " # rev_count=0  \n",
    "\n",
    " #print (money,cousines,tot_count,rev_count)\n",
    " return money,cousines\n",
    " #.contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "saving point\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "no connection/empty data\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n",
      "saving point\n"
     ]
    }
   ],
   "source": [
    "#заполняем недостающие данные с оригинального сайта и сохраням данные в файл после обработки каждых 100 записей.\n",
    "k=0\n",
    "\n",
    "for i in range (0,len(df)-1):\n",
    "            \n",
    "    if pd.isna(df.loc[i,'Cuisine Style']):\n",
    "        df.loc[i,['Price Range','Cuisine Style']]=get_data(df.loc[i,'URL_TA'])\n",
    "        k+=1\n",
    "    if k==100:\n",
    "        df.loc[0,'proc_count']=i\n",
    "        df.to_csv('main_task_enriched_Price_Cuisine.csv')\n",
    "        print ('saving point')\n",
    "        k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
